{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"machine_translation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Yo_0EkY9Tfl2","colab_type":"text"},"source":["## Machine translation for English - Vietnamese\n","* Skip these lines if not using Google Colab"]},{"cell_type":"code","metadata":{"id":"ujdku9UdIQXQ","colab_type":"code","outputId":"f50aedac-6d25-4e3f-c5c9-cf6679b64cee","executionInfo":{"status":"ok","timestamp":1572132653497,"user_tz":-420,"elapsed":12844,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U0cXBXoFI5V1","colab_type":"code","outputId":"1dc59751-53dd-411e-df42-72e2ded59f48","executionInfo":{"status":"ok","timestamp":1572132654765,"user_tz":-420,"elapsed":1256,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd 'drive/My Drive/Colab Notebooks/machine_translation'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/machine_translation\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-zMgY1F3TpXi","colab_type":"text"},"source":["* Import necessary functions"]},{"cell_type":"code","metadata":{"id":"04wloRvxJnZC","colab_type":"code","colab":{}},"source":["from dataset import MTDataset\n","from model import Encoder, Decoder\n","from language import Language\n","from utils import preprocess, generate_seed\n","from train import train\n","from eval import validate\n","from translate import translate"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BJ3X_Zv7breH","colab_type":"text"},"source":["### Preparing data\n","* Preprocess input and target sentences for train, val and test set: remove all digits and punctuation, take only input - target pairs of sentences with length shorter than *MAX_LEN*. Here I choose max length = 20 for faster training."]},{"cell_type":"code","metadata":{"id":"H4ikOy3wh-MW","colab_type":"code","colab":{}},"source":["MAX_LEN = 20\n","sentences_inp_train, sentences_trg_train = preprocess('datasets/train/train.en', 'datasets/train/train.vi', max_len=MAX_LEN)\n","sentences_inp_val, sentences_trg_val = preprocess('datasets/dev/tst2012.en', 'datasets/dev/tst2012.vi', max_len=MAX_LEN)\n","sentences_inp_test, sentences_trg_test = preprocess('datasets/test/tst2013.en', 'datasets/test/tst2013.vi', max_len=MAX_LEN)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4fwCE6eLc8Ny","colab_type":"text"},"source":["* Create Language class for each set, each class will contain information like **max length, all sentences, word_to_indices and indices_to_word, vocab size and word vectors**. For validation set and test set, the **word_to_indices** and **indices_to_word** are retrieved from training set."]},{"cell_type":"code","metadata":{"id":"nf7zXMP8J3zv","colab_type":"code","colab":{}},"source":["train_inp = Language(sentences_inp_train)\n","train_trg = Language(sentences_trg_train)\n","\n","val_inp = Language(sentences_inp_val, train=False, word2id=train_inp.word2id, id2word=train_inp.id2word)\n","val_trg = Language(sentences_trg_val, train=False, word2id=train_trg.word2id, id2word=train_trg.id2word)\n","\n","test_inp = Language(sentences_inp_test, train=False, word2id=train_inp.word2id, id2word=train_inp.id2word)\n","test_trg = Language(sentences_trg_test, train=False, word2id=train_trg.word2id, id2word=train_trg.id2word)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_HrsC4GhfFIi","colab_type":"text"},"source":["* Create Dataset classes"]},{"cell_type":"code","metadata":{"id":"QE2InnNDKDBu","colab_type":"code","colab":{}},"source":["train_set = MTDataset(train_inp.wordvec, train_trg.wordvec)\n","val_set = MTDataset(val_inp.wordvec, val_trg.wordvec)\n","test_set = MTDataset(test_inp.wordvec, test_trg.wordvec)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qv0We_-pKmju","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader\n","import torch\n","import torch.nn as nn\n","from torch.optim.lr_scheduler import StepLR"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uNIWJiOSfR96","colab_type":"text"},"source":["* Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"_KMGqO4XKogV","colab_type":"code","colab":{}},"source":["train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_set, batch_size=64)\n","test_loader = DataLoader(test_set, batch_size=64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8_Zvpn0gfVaY","colab_type":"text"},"source":["* Model's parameters"]},{"cell_type":"code","metadata":{"id":"0tLM3sGkKpkn","colab_type":"code","colab":{}},"source":["Tx, Ty = train_inp.max_len, train_trg.max_len\n","vocab_size_inp, vocab_size_trg = train_inp.vocab_size, train_trg.vocab_size\n","embedding_dim = 256\n","hidden_size = 1024"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L3DErLwUf_HR","colab_type":"text"},"source":["### Building models"]},{"cell_type":"code","metadata":{"id":"2fTREhkn7aAb","colab_type":"code","colab":{}},"source":["if torch.cuda.is_available():\n","    device='cuda'\n","else:\n","    device='cpu'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CegamxGATO3g","colab_type":"code","colab":{}},"source":["# choose a seed for both models for consistent results\n","SEED = 5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FxZ3niz9gC-Z","colab_type":"text"},"source":["* **Model 1: first hidden state of Decoder are the same as original paper.**"]},{"cell_type":"code","metadata":{"id":"_7ZNOMCbLu5T","colab_type":"code","colab":{}},"source":["generate_seed(SEED)  # generate seed to ensure consistent result each run\n","encoder_1 = Encoder(vocab_size_inp, embedding_dim, hidden_size).to(device=device)\n","decoder_1 = Decoder(hidden_size, vocab_size_trg, embedding_dim).to(device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"63pvOPrCLAUm","colab_type":"code","colab":{}},"source":["optimizer_1 = torch.optim.Adam(params=list(encoder_1.parameters()) + list(decoder_1.parameters()))\n","criterion_1 = nn.CrossEntropyLoss()\n","scheduler_1 = StepLR(optimizer_1, step_size=2, gamma=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Jlp16wzvtW5","colab_type":"code","outputId":"9a40ca82-7a31-4ed8-d8a6-2b5e84ba9c74","executionInfo":{"status":"ok","timestamp":1572111302556,"user_tz":-420,"elapsed":3743489,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":782}},"source":["# train model, save best state dict\n","statedict_1 = train(encoder_1, decoder_1, train_loader, val_loader, optimizer_1, criterion_1, train_trg.id2word, scheduler_1, 5, 200, device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch  1\n","Iter 0, loss = 9.013927\n","Iter 200, loss = 2.750423\n","Iter 400, loss = 2.298985\n","Iter 600, loss = 2.248380\n","Iter 800, loss = 1.933960\n","Iter 1000, loss = 1.963099\n","Validation BLEU score: 0.113232\n","\n","Epoch  2\n","Iter 0, loss = 1.641850\n","Iter 200, loss = 1.793719\n","Iter 400, loss = 1.429143\n","Iter 600, loss = 1.457869\n","Iter 800, loss = 1.443988\n","Iter 1000, loss = 1.496264\n","Validation BLEU score: 0.135118\n","\n","Epoch  3\n","Iter 0, loss = 1.053230\n","Iter 200, loss = 0.966383\n","Iter 400, loss = 1.037764\n","Iter 600, loss = 1.063965\n","Iter 800, loss = 0.900151\n","Iter 1000, loss = 1.001884\n","Validation BLEU score: 0.158528\n","\n","Epoch  4\n","Iter 0, loss = 0.737438\n","Iter 200, loss = 0.766254\n","Iter 400, loss = 0.687951\n","Iter 600, loss = 0.783305\n","Iter 800, loss = 0.771455\n","Iter 1000, loss = 0.810231\n","Validation BLEU score: 0.159650\n","\n","Epoch  5\n","Iter 0, loss = 0.649854\n","Iter 200, loss = 0.619188\n","Iter 400, loss = 0.510352\n","Iter 600, loss = 0.535633\n","Iter 800, loss = 0.545049\n","Iter 1000, loss = 0.547665\n","Validation BLEU score: 0.161177\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PDS1mhEDNBVE","colab_type":"code","colab":{}},"source":["# save state dict into a file\n","torch.save(statedict_1, 'saved_models/statedict_1.pth') #  save model's state dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TS1WkfMpszB","colab_type":"code","outputId":"3b3fd3ab-3c08-4852-ab25-0451f990f028","executionInfo":{"status":"ok","timestamp":1572132696104,"user_tz":-420,"elapsed":35347,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# load state dict\n","statedict_1 = torch.load('saved_models/statedict_1.pth')\n","encoder_1.load_state_dict(statedict_1['encoder'])\n","decoder_1.load_state_dict(statedict_1['decoder'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"XRamOiX5gbyO","colab_type":"text"},"source":["* **Model 2 (modified version): initial hidden state h0 of Decoder is created from Encoder's last forward and last backward hidden states.**"]},{"cell_type":"code","metadata":{"id":"-qza4wCzgmFs","colab_type":"code","colab":{}},"source":["# modified = True means different variant from paper\n","generate_seed(SEED)\n","encoder_2 = Encoder(vocab_size_inp, embedding_dim, hidden_size, modified=True).to(device=device)\n","decoder_2 = Decoder(hidden_size, vocab_size_trg, embedding_dim).to(device=device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qCPQZH_FEjZb","colab_type":"code","colab":{}},"source":["optimizer_2 = torch.optim.Adam(params=list(encoder_2.parameters()) + list(decoder_2.parameters()))\n","criterion_2 = nn.CrossEntropyLoss()\n","scheduler_2 = StepLR(optimizer_2, step_size=2, gamma=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYZB7IY0Emyz","colab_type":"code","outputId":"5314b595-d28b-4da6-a8dc-d07818346c19","executionInfo":{"status":"ok","timestamp":1572062583173,"user_tz":-420,"elapsed":3068477,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":731}},"source":["# train model\n","statedict_2 = train(encoder_2, decoder_2, train_loader, val_loader, optimizer_2, criterion_2, train_trg.id2word, scheduler_2, 5, 200, device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch  1\n","Iter 0, loss = 8.985854\n","Iter 200, loss = 2.694446\n","Iter 400, loss = 2.147349\n","Iter 600, loss = 2.028440\n","Iter 800, loss = 2.440283\n","Iter 1000, loss = 2.084523\n","Validation BLEU score: 0.121072\n","\n","Epoch  2\n","Iter 0, loss = 1.484097\n","Iter 200, loss = 1.635226\n","Iter 400, loss = 1.487907\n","Iter 600, loss = 1.590866\n","Iter 800, loss = 1.401913\n","Iter 1000, loss = 1.591312\n","Validation BLEU score: 0.135914\n","\n","Epoch  3\n","Iter 0, loss = 1.099661\n","Iter 200, loss = 0.975920\n","Iter 400, loss = 1.067758\n","Iter 600, loss = 1.179304\n","Iter 800, loss = 0.907614\n","Iter 1000, loss = 0.964632\n","Validation BLEU score: 0.159819\n","\n","Epoch  4\n","Iter 0, loss = 0.740380\n","Iter 200, loss = 0.679936\n","Iter 400, loss = 0.850062\n","Iter 600, loss = 0.767678\n","Iter 800, loss = 0.733945\n","Iter 1000, loss = 0.789158\n","Validation BLEU score: 0.159320\n","\n","Epoch  5\n","Iter 0, loss = 0.580725\n","Iter 200, loss = 0.512373\n","Iter 400, loss = 0.596796\n","Iter 600, loss = 0.521631\n","Iter 800, loss = 0.481102\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gksz9flFE1mb","colab_type":"code","colab":{}},"source":["# save state dict\n","torch.save(statedict_2, 'saved_models/statedict_2.pth')  #  save model's state dict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZA7ABsxvB4b","colab_type":"code","outputId":"bcd3de05-0117-4090-bd70-afa553409743","executionInfo":{"status":"ok","timestamp":1572132700672,"user_tz":-420,"elapsed":4538,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# load state dict\n","statedict_2 = torch.load('saved_models/statedict_2.pth')\n","encoder_2.load_state_dict(statedict_2['encoder'])\n","decoder_2.load_state_dict(statedict_2['decoder'])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"P0UWu5mYP8L5","colab_type":"text"},"source":["### Validate BLEU-4 score on test set"]},{"cell_type":"code","metadata":{"id":"Z_D3rm_Ysnnv","colab_type":"code","outputId":"98c8afc7-4d26-4e0d-d60f-f9ab6cdbfe13","executionInfo":{"status":"ok","timestamp":1572132886223,"user_tz":-420,"elapsed":5311,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print('Model 1 BLEU score: %.3f' %(100*validate(test_loader, encoder_1, decoder_1, test_trg.id2word, device)))\n","print('Model 2 BLEU score: %.3f' %(100*validate(test_loader, encoder_2, decoder_2, test_trg.id2word, device)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model 1 BLEU score: 18.524\n","Model 2 BLEU score: 19.283\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2re8jXZdXBG_","colab_type":"text"},"source":["### Test time\n","**1. Sentence 1**"]},{"cell_type":"code","metadata":{"id":"VScUEWDVF4mU","colab_type":"code","outputId":"e6a1b4c0-10af-4308-9095-1c514127e022","executionInfo":{"status":"ok","timestamp":1572134791942,"user_tz":-420,"elapsed":1563,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["sentence = sentences_inp_test[0]\n","print(\"Sentence: \" + sentence)\n","print(\"Model 1: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_1, decoder_1, MAX_LEN, device))\n","print(\"Model 2: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_2, decoder_2, MAX_LEN, device))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sentence: and i was very proud\n","Model 1: và tôi rất tự hào\n","Model 2: và tôi tự hào rất tự hào\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iyA3DOGsdM3a","colab_type":"text"},"source":["**2. Sentence 2**"]},{"cell_type":"code","metadata":{"id":"BQLxncFAglp0","colab_type":"code","outputId":"5ac5bc5d-6ae3-4104-d8f6-0e62f437b69d","executionInfo":{"status":"ok","timestamp":1572134794947,"user_tz":-420,"elapsed":1223,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["sentence = sentences_inp_test[50]\n","print(\"Sentence: \" + sentence)\n","print(\"Model 1: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_1, decoder_1, MAX_LEN, device))\n","print(\"Model 2: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_2, decoder_2, MAX_LEN, device))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sentence: but most people don apost agree\n","Model 1: nhưng hầu hết mọi người không đồng ý\n","Model 2: nhưng hầu hết mọi người không đồng ý\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cvUpYd3JhOn4","colab_type":"text"},"source":["**3. Sentence 3**"]},{"cell_type":"code","metadata":{"id":"cwhqaflbP8c9","colab_type":"code","outputId":"f90b8298-ffc4-4232-b826-43689b2958cf","executionInfo":{"status":"ok","timestamp":1572134798021,"user_tz":-420,"elapsed":1168,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["sentence = sentences_inp_test[100]\n","print(\"Sentence: \" + sentence)\n","print(\"Model 1: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_1, decoder_1, MAX_LEN, device))\n","print(\"Model 2: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_2, decoder_2, MAX_LEN, device))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sentence: i also didn apost know that the second step is to isolate the victim\n","Model 1: tôi cũng không biết rằng thứ hai là để phân loại các nạn nhân\n","Model 2: tôi cũng không biết rằng bước thứ hai là để chuyển nạn nhân\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AGpHjDk1hVqp","colab_type":"text"},"source":["**4. Sentence 4**"]},{"cell_type":"code","metadata":{"id":"n7FNEFuSul6b","colab_type":"code","outputId":"cf9ed6f4-2d82-45ba-b7c2-b97d2cba5721","executionInfo":{"status":"ok","timestamp":1572134800742,"user_tz":-420,"elapsed":1164,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["sentence = sentences_inp_test[1]\n","print(\"Sentence: \" + sentence)\n","print(\"Model 1: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_1, decoder_1, MAX_LEN, device))\n","print(\"Model 2: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_2, decoder_2, MAX_LEN, device))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sentence: my family was not poor  and myself  i had never experienced hunger\n","Model 1: gia đình tôi không phải là nghèo và tôi không bao giờ hồi phục hồi\n","Model 2: gia đình tôi không nghèo và tôi không bao giờ có thể nhìn qua đói\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ziC31StYiVut","colab_type":"text"},"source":["**5. Sentence 5**"]},{"cell_type":"code","metadata":{"id":"GNF4z_bzMo7i","colab_type":"code","outputId":"a9b46ebe-54a6-4732-a8a3-a1bda17879cf","executionInfo":{"status":"ok","timestamp":1572134828322,"user_tz":-420,"elapsed":1188,"user":{"displayName":"Tu Ngo","photoUrl":"","userId":"03418550170857508052"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["sentence = sentences_inp_test[3]\n","print(\"Sentence: \" + sentence)\n","print(\"Model 1: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_1, decoder_1, MAX_LEN, device))\n","print(\"Model 2: \" + translate(sentence, train_inp.word2id, train_trg.word2id, train_trg.id2word, encoder_2, decoder_2, MAX_LEN, device))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sentence: this was the first time i heard that people in my country were suffering\n","Model 1: lần đầu tiên tôi nghe thấy mọi người ở đất nước của tôi bị đau khổ\n","Model 2: đó là lần đầu tiên tôi nghe thấy mọi người ở đất nước của tôi rất đau khổ\n"],"name":"stdout"}]}]}